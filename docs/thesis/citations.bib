@misc{ppo2017,
  author = "Schulman, J. and Wolski, F. and Dhariwal, P. and Radford, A. and Klimov, O.",
  title = "Proximal Policy Optimization Algorithms",
  year = "2017",
  url = "https://doi.org/10.48550/arXiv.1707.06347"
}

@article{autonomousvessels2019,
  author = "Gu, Yewen and Góez, Julio and Guajardo, Mario and Wallace, Stein W.",
  title = "Autonomous Vessels: State of the Art and Potential Opportunities in Logistics",
  year = "2019",
  journal = "NHH Dept. of Business and Management Science Discussion Paper",
  number = "2019/6",
  url = "http://dx.doi.org/10.2139/ssrn.3448420"
}

@article{ferreira2020,
  author = "Ferreira, F. and Quattrini Li, A. and Rødseth, Ø. J.",
  title = "Editorial: Navigation and Perception for Autonomous Surface Vessels",
  year = "2022",
  journal = "Frontiers in Robotics and AI",
  url = "https://doi.org/10.3389/frobt.2022.918464"
}

@article{christensen2022,
  author = "Christensen, L. and de Gea Fernández, J. and Hildebrandt, M. et al.",
  title = "Recent Advances in AI for Navigation and Control of Underwater Robots",
  year = "2022",
  journal = "Curr Robot Rep",
  url = "https://doi.org/10.1007/s43154-022-00088-3"
}

@article{wang2023,
  author = "Wang, C. and Zhang, X. and Yang, Z. and Bashir, M. and Lee, K.",
  title = "Collision avoidance for autonomous ships using deep reinforcement learning and prior-knowledge-based approximate representation",
  year = "2023",
  journal = "Frontiers in Marine Science",
  volume = "9",
  pages = "1084763",
  url = "https://doi.org/10.3389/fmars.2022.1084763"
}

@misc{sac2018,
  author = "Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey",
  title = "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor",
  year = "2018",
  url = "https://doi.org/10.48550/arXiv.1801.01290"
}

@online{alphastar2019,
  author = "DeepMind",
  title = "AlphaStar: Mastering the real-time strategy game StarCraft II",
  year = "2019",
  url = "https://www.deepmind.com/blog/alphastar-mastering-the-real-time-strategy-game-starcraft-ii"
}

@online{aihabitat,
  title = "AI Habitat Website",
  url = "https://aihabitat.org/"
}

@online{deepmindcontrolsuite2018,
  title = "DeepMind Control Suite",
  url = "https://www.deepmind.com/open-source/deepmind-control-suite"
}

@online{deeplab2016,
  title = "DeepMind Lab",
  url = "https://www.deepmind.com/open-source/deepmind-lab"
}

@online{mujoco,
  title = "MuJoCo Website",
  url = "https://mujoco.org/"
}

@online{ros,
  title = "ROS Website",
  url = "https://www.ros.org/"
}

@online{gazebosim,
  title = "GazeboSim Website",
  url = "https://gazebosim.org/home"
}

@online{unity3d,
  title = "Unity3D Website",
  url = "https://www.unity.com/"
}

@online{mlagents,
  title = "MLAgents Website",
  url = "https://github.com/Unity-Technologies/ml-agents"
}

@article{neptuneai2023,
  author = "Januszewski, P.",
  title = "Best Benchmarks for Reinforcement Learning: The Ultimate List",
  year = "2023",
  journal = "Neptune.ai",
  url = "https://neptune.ai/blog/best-benchmarks-for-reinforcement-learning"
}

@article{habitat2019,
  author = "Savva, M. and Kadian, A. and Maksymets, O. et al.",
  title = "Habitat: A Platform for Embodied AI Research",
  year = "2019",
  journal = "arXiv preprint",
  url = "https://doi.org/10.48550/arXiv.1904.01201"
}

@article{habitat2021,
  author = "Szot, A. and Clegg, A. and Undersander, E. et al.",
  title = "Habitat 2.0: Training Home Assistants to Rearrange their Habitat",
  year = "2021",
  journal = "arXiv preprint",
  url = "https://doi.org/10.48550/arXiv.2106.14405"
}

@online{mujocodocs,
  title = "MuJoCo Documentation",
  url = "https://mujoco.readthedocs.io/en/latest/overview.html"
}

@online{thorndikewiki,
  title = "Wikipedia: Edward Thorndike",
  url = "https://en.wikipedia.org/wiki/Edward_Thorndike"
}

@inproceedings{nowe2012,
  author = "Nowé, A. and Vrancx, P. and De Hauwere, YM.",
  title = "Game Theory and Multi-agent Reinforcement Learning",
  year = "2012",
  booktitle = "Reinforcement Learning. Adaptation, Learning, and Optimization",
  volume = "12",
  publisher = "Springer",
  url = "https://doi.org/10.1007/978-3-642-27645-3_14"
}

@article{busoniu2018,
  author = "Buşoniu, L. and de Bruin, T. and Tolić, D. and Kober, J. and Palunko, I.",
  title = "Reinforcement learning for control: Performance, stability, and deep approximators",
  year = "2018",
  journal = "Annual Reviews in Control",
  volume = "46",
  url = "https://doi.org/10.1016/j.arcontrol.2018.09.005"
}

@article{hubbs2020,
  author = "Hubbs, C. D. and Perez, H. D. and Sarwar, O. et al.",
  title = "OR-Gym: A Reinforcement Learning Library for Operations Research Problems",
  year = "2020",
  url = "https://doi.org/10.48550/arXiv.2008.06319"
}

@article{russo2015,
  author = "Daniel Russo and Benjamin Van Roy",
  title = "An information-theoretic analysis of Thompson sampling",
  year = "2015",
  journal = "Journal of Machine Learning Research",
  volume = "17",
  url = "https://theinformaticists.com/2021/03/19/an-application-of-information-theory-in-reinforcement-learning/"
}

@book{gosavi2018,
  author = "Gosavi, A.",
  title = "Simulation-Based Optimization: Parametric Optimization Techniques and Reinforcement Learning",
  year = "2018",
  publisher = "Springer",
  url = "https://link.springer.com/book/10.1007/978-1-4757-3766-0"
}

@article{zhang2019,
  author = "Zhang, K. and Yang, Z. and Başar, T.",
  title = "Multi-Agent Reinforcement Learning: A Selective Overview of Theories and Algorithms",
  year = "2019",
  journal = "ArXiv preprint",
  url = "https://arxiv.org/abs/1911.10635"
}

@book{suttonandbarto2018,
  author = "Sutton, R.S. and Barto, A.G.",
  title = "Reinforcement Learning: An Introduction",
  year = "2018",
  edition = "2nd",
  publisher = "MIT Press",
}

@book{aima2022,
  author = "Russell, S. and Norvig, P.",
  title = "Artificial Intelligence: A Modern Approach",
  year = "2022",
  edition = "4th US ed.",
  url = "https://aima.cs.berkeley.edu/"
}

@article{alphago2016,
  author = "Silver, D. and Huang, A. and Maddison, C. et al.",
  title = "Mastering the game of Go with deep neural networks and tree search",
  year = "2016",
  journal = "Nature",
  volume = "529",
  url = "https://doi.org/10.1038/nature16961"
}

@article{mnih2015,
  author = "Mnih, V. and Kavukcuoglu, K. and Silver, D. et al.",
  title = "Human-level control through deep reinforcement learning",
  year = "2015",
  journal = "Nature",
  volume = "518",
  url = "https://doi.org/10.1038/nature14236"
}

@article{lillicrap2015,
  author = "Lillicrap, T. P. and Hunt, J. J. and Pritzel, A. et al.",
  title = "Continuous control with deep reinforcement learning",
  year = "2015",
  url = "https://arxiv.org/abs/1509.02971"
}

@article{bojarski2016,
  author = "M. Bojarski and D. Del Testa and D. Dworakowski et al.",
  title = "End to End Learning for Self-Driving Cars",
  year = "2016",
  url = "https://arxiv.org/abs/1604.07316"
}

@article{horgan2018,
  author = "D. Horgan and J. Quan and D. Budden et al.",
  title = "Distributed Prioritized Experience Replay",
  year = "2018",
  url = "https://arxiv.org/abs/1803.00933"
}

@article{fortunato2017,
  author = "M. Fortunato and M. G. Azar and B. Piot et al.",
  title = "Noisy Networks for Exploration",
  year = "2017",
  url = "https://arxiv.org/abs/1706.10295"
}

@article{mankowitz2019,
  author = "D. Mankowitz and T. Hester",
  title = "Challenges of Real-World Reinforcement Learning",
  year = "2019",
  url = "https://arxiv.org/abs/1904.12901"
}

@article{mnih2016,
  author = "V. Mnih and A. P. Badia and M. Mirza et al.",
  title = "Asynchronous Methods for Deep Reinforcement Learning",
  year = "2016",
  journal = "ArXiv preprint",
  url = "https://doi.org/10.48550/arXiv.1602.01783"
}

@online{unitywiki,
  title = "Wikipedia: Unity game engine",
  url = "https://en.wikipedia.org/wiki/Unity_(game_engine)"
}

@online{unitycontract2022,
  title = "Unity Signs Multi-Million Dollar Contract To Help U.S. Army And Defense Agencies",
  url = "https://kotaku.com/unity-new-contract-us-government-military-army-engine-1849403118"
}

@online{blenderdocs,
  title = "Blender Documentation",
  url = "https://docs.blender.org/manual/en/latest/getting_started/about/introduction.html"
}

@online{blenderweb,
  title = "Blender Website",
  url = "https://www.blender.org/features/modeling/"
}

@online{blendergis,
  title = "BlenderGIS Website",
  url = "https://github.com/domlysz/BlenderGIS"
}

@online{mlagentscode,
  title = "MLAgents code repository",
  url = "https://unity-technologies.github.io/ml-agents/"
}

@online{mlagentsdocs,
  title = "MLAgents documentation",
  url = "https://docs.unity3d.com/Packages/com.unity.ml-agents@2.0/manual/index.html"
}

@article{montezumasrevenge2018,
  author = "A. Juliani",
  title = "On “solving” Montezuma’s Revenge Looking beyond the hype of recent Deep RL successes",
  year = "2018",
  url = "https://awjuliani.medium.com/on-solving-montezumas-revenge-2146d83f0bc3"
}

@online{waypointwiki,
  title = "Wikipedia: Waypoint",
  url = "https://en.wikipedia.org/wiki/Waypoint"
}

@article{zhu2022,
  author = "Jie Zhu and Fengge Wu and Junsuo Zhao",
  title = "An Overview of the Action Space for Deep Reinforcement Learning",
  year = "2022",
  url = "https://doi.org/10.1145/3508546.3508598"
}

@article{kanervisto2020,
  author = " A. Kanervisto and C. Scheller and V. Hautamäki ",
  title = "Action Space Shaping in Deep Reinforcement Learning",
  year = "2020",
  url = "https://doi.org/10.48550/arXiv.2004.00980"
}

@online{spatialdistance2020,
  title = "Spatial Distance and Machine Learning. Distance Metrics and Feature Engineering Using Longitude and Latitude Data",
  url = "https://towardsdatascience.com/spatial-distance-and-machine-learning-2cab72fc6284"
}

@online{geolocationml2021,
  title = "Leveraging Geolocation Data for Machine Learning: Essential Techniques. A Gentle Guide to Feature Engineering and Visualization with Geospatial data",
  url = "https://towardsdatascience.com/leveraging-geolocation-data-for-machine-learning-essential-techniques-192ce3a969bc"
}

@article{cpo2017,
  author = "J. Achiam and D. Held and A. Tamar and P. Abbeel",
  title = "Constrained policy optimization",
  year = "2017",
  url = "https://dl.acm.org/doi/10.5555/3305381.3305384"
}

@online{intcatch,
  title = "Intcatch Website",
  url = "https://www.intcatch.eu/"
}

@online{intcatcheuro,
  title = "Europe - Development and application of Novel, Integrated Tools for monitoring and managing Catchments",
  url = "https://cordis.europa.eu/project/id/689341/results"
}


@online{dxvksteamcommunity,
  title = "DXVK (DirectX-over-Vulkan) stability improvements \& potential performance boost: installation guide \& details",
  url = "https://steamcommunity.com/sharedfiles/filedetails/?id=2461019058"
}

@online{dxvklc2020,
  title = "Improve Your Wine Gaming on Linux With DXVK",
  url = "https://linuxconfig.org/improve-your-wine-gaming-on-linux-with-dxvk"
}